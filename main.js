// IMPORTANT: Replace the API key below with your own OpenAI key before running

import { startRecording, stopRecording } from "./modules/recorder.js";
import { transcribeAudio } from "./modules/whisper.js";
import { extractIntent } from "./modules/gpt.js";
import { addTask, listTasks, clearTasks } from "./modules/tasks.js";
import { speak } from "./modules/tts.js";

// âœ… Wait for the DOM to be ready before running the logic
window.addEventListener("DOMContentLoaded", () => {
  const OPENAI_API_KEY = "YOUR OPENAI API KEY HERE"; // Replace with your actual OpenAI API key
  console.log("ğŸ” OpenAI Key Loaded:", OPENAI_API_KEY);

  const recordBtn = document.getElementById("recordBtn");
  const statusText = document.getElementById("status");
  const transcriptDiv = document.getElementById("transcript");
  const taskList = document.getElementById("taskList");

  // âœ… Check if HTML elements were found
  if (!recordBtn || !statusText || !transcriptDiv || !taskList) {
    console.error("âŒ One or more UI elements are missing.");
    return;
  }

  // ğŸ™ï¸ Button click handler
  recordBtn.onclick = () => {
    if (recordBtn.textContent.includes("Start")) {
      console.log("â–¶ï¸ Starting Recording...");
      startRecording(handleAudio, updateUI);
    } else {
      console.log("â¹ï¸ Stopping Recording...");
      stopRecording(updateUI);
    }
  };

  // ğŸ” Updates UI status and button text
  function updateUI(state) {
    console.log("ğŸ”„ UI Update State:", state);
    if (state === "listening") {
      statusText.textContent = "ğŸ¤ Listening...";
      recordBtn.textContent = "â¹ Stop Recording";
    } else if (state === "processing") {
      statusText.textContent = "Processing...";
      recordBtn.textContent = "ğŸ™ï¸ Start Recording";
    }
  }

  // ğŸ§  Handle the audio blob returned from recorder
  async function handleAudio(audioBlob) {
    try {
      const transcript = await transcribeAudio(audioBlob, OPENAI_API_KEY);
      console.log("ğŸ“ Transcript Received:", transcript);
      transcriptDiv.textContent = `ğŸ“ You said: ${transcript}`;

      const structured = await extractIntent(transcript, OPENAI_API_KEY);
      console.log("ğŸ§  Intent Structured Data:", structured);

      if (structured.intent === "add_task") {
        addTask(structured, taskList);
        speak(`Task added: ${structured.task}`);
      } else if (structured.intent === "list_tasks") {
        listTasks(taskList);
        speak("Here are your tasks.");
      } else if (structured.intent === "clear_all") {
        clearTasks(taskList);
        speak("All tasks cleared.");
      } else {
        speak("Sorry, I didnâ€™t understand that.");
      }
    } catch (err) {
      console.error("âŒ Error processing audio:", err);
      speak("Sorry, something went wrong.");
    }
  }
});
